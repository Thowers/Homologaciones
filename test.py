from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch
import re

MODEL_NAME = "mrm8488/mt5-small-finetuned-spanish-summarization"

print("游댳 Cargando modelo, esto puede tardar unos segundos...")
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)

# Forzar CPU
device = torch.device("cpu")
model.to(device)
print(f"游 Dispositivo activo: {device}")

def limpiar_texto(texto: str) -> str:
    # Limpieza b치sica del texto
    texto = re.sub(r"\s+", " ", texto)
    texto = texto.strip().capitalize()
    return texto

def generar_descripcion(nombre_materia: str) -> str:
    prompt = (
        f"Redacta una descripci칩n acad칠mica formal y clara en espa침ol sobre la asignatura universitaria '{nombre_materia}'. "
        "Incluye los temas principales de estudio y los objetivos de aprendizaje."
    )

    # Tokenizar entrada
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=128).to(device)

    # Generar descripci칩n
    outputs = model.generate(
        **inputs,
        max_length=150,
        num_beams=5,
        do_sample=True,
        top_p=0.95,
        top_k=50,
        early_stopping=True
    )

    descripcion = tokenizer.decode(outputs[0], skip_special_tokens=True)
    descripcion = limpiar_texto(descripcion)

    # En caso de texto muy corto, usar fallback
    if len(descripcion.split()) < 10:
        descripcion = (
            f"La asignatura {nombre_materia} estudia los fundamentos te칩ricos y pr치cticos del 치rea, "
            "abarcando conceptos esenciales y aplicaciones formales."
        )

    return descripcion

if __name__ == "__main__":
    materia = input("游닂 Ingresa el nombre de la materia: ")
    descripcion = generar_descripcion(materia)
    print("\n游 Descripci칩n generada:\n")
    print(descripcion)
